{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18572c07-8f7a-4b25-8fbc-7b27022bd9d9",
   "metadata": {},
   "source": [
    "`1` Takes (pickup signals, coil currents, p-profile) --> poloidal flux map --> Classification of limiter or diverted and identification of LCFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac145f-e246-4d4a-96fb-f6db940de95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostname\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399bf7b-b849-4046-88a9-2d1e72136f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55efa79e-b05f-4548-b2b8-6eef4ae30475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 00:01:55.535734: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.16.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"   \n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import matlib as mb\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import random\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import (r2_score, f1_score, accuracy_score, \n",
    "                             roc_curve, roc_auc_score, mean_squared_error)\n",
    "\n",
    "import scipy.interpolate as interp\n",
    "from scipy import interpolate, signal\n",
    "import scipy.ndimage\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import mat73\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f4e589-1341-46b4-962b-1aecd212b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename='/home/arunavk/ML-GS/ML_MSE/ARC_like_equilibrium_dataset.mat'\n",
    "mat = scipy.io.loadmat(filename)\n",
    "for key,val in mat.items():\n",
    "    print(key)\n",
    "    exec(key + '=val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca8c90-1028-4794-b672-24927e210a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = 'float32'\n",
    "\n",
    "DB_meas_Bpickup_test_ConvNet = mat['DB_meas_Bpickup_test_ConvNet'].astype(DTYPE)\n",
    "DB_coils_curr_test_ConvNet   = mat['DB_coils_curr_test_ConvNet'].astype(DTYPE)\n",
    "DB_p_test_ConvNet            = mat['DB_p_test_ConvNet'].astype(DTYPE)\n",
    "res_RHS_pixel_data_load      = mat['DB_res_RHS_pixel_test_ConvNet'].astype(DTYPE)\n",
    "\n",
    "RR_pixels                    = mat['RR_pixels'].astype(DTYPE)\n",
    "ZZ_pixels                    = mat['ZZ_pixels'].astype(DTYPE)\n",
    "\n",
    "DB_res_RHS_pixel_test_ConvNet   = mat['DB_res_RHS_pixel_test_ConvNet'].astype(DTYPE)\n",
    "DB_separatrix_200_test_ConvNet  = mat['DB_separatrix_200_test_ConvNet'].astype(DTYPE)\n",
    "XP_YN                           = mat[\"XP_YN\"]                    # optional (diverted vs limiter)\n",
    "\n",
    "DB_psi_pixel_test_ConvNet    = mat['DB_psi_pixel_test_ConvNet'].astype(DTYPE)\n",
    "DB_Jpla_pixel_test_ConvNet   = mat['DB_Jpla_pixel_test_ConvNet'].astype(DTYPE)\n",
    "\n",
    "print(\"DB_meas_Bpickup_test_ConvNet shape:\", DB_meas_Bpickup_test_ConvNet.shape)\n",
    "print(\"DB_coils_curr_test_ConvNet shape:   \", DB_coils_curr_test_ConvNet.shape)\n",
    "print(\"DB_p_test_ConvNet shape:            \", DB_p_test_ConvNet.shape)\n",
    "print(\"DB_psi_pixel_test_ConvNet shape:    \", DB_psi_pixel_test_ConvNet.shape)\n",
    "print(\"RR_pixels shape:                    \", RR_pixels.shape)\n",
    "print(\"ZZ_pixels shape:                    \", ZZ_pixels.shape)\n",
    "print(\"XP_YN shape:                        \", XP_YN.shape)\n",
    "print(\"DB_separatrix_200_test_ConvNet shape:\", DB_separatrix_200_test_ConvNet.shape)\n",
    "print(\"res_RHS_pixel_data_load shape:      \", res_RHS_pixel_data_load.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "ind_plot = np.random.randint(0,DB_Jpla_pixel_test_ConvNet.shape[0],1)[0]\n",
    "print(ind_plot)\n",
    "for i in range(1,1000):\n",
    "    plt.plot(DB_separatrix_200_test_ConvNet[i,:,0],DB_separatrix_200_test_ConvNet[i,:,1])\n",
    "    plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1):\n",
    "    ind_plot = np.random.randint(0,DB_Jpla_pixel_test_ConvNet.shape[0],1)[0]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(9, 5), sharey=True)\n",
    "    img = axs[0].contour(RR_pixels,ZZ_pixels,DB_psi_pixel_test_ConvNet[ind_plot,:,:],15)\n",
    "    fig.colorbar(img)\n",
    "    axs[0].plot(\n",
    "        DB_separatrix_200_test_ConvNet[ind_plot,:,0],\n",
    "        DB_separatrix_200_test_ConvNet[ind_plot,:,1],\n",
    "        c='g')\n",
    "    axs[0].axis('equal')\n",
    "    axs[0].set_xlabel('r [m]')\n",
    "    axs[0].set_ylabel('z [m]')\n",
    "    axs[0].set_title('$\\Psi$ [Wb] - equil. #{}'.format(ind_plot))\n",
    "    img = axs[1].contourf(RR_pixels,ZZ_pixels,DB_Jpla_pixel_test_ConvNet[ind_plot,:,:],15)\n",
    "    fig.colorbar(img)\n",
    "    axs[1].axis('equal')\n",
    "    axs[1].set_title('$J_\\phi$ [A/m2] - equil. #{}'.format(ind_plot))\n",
    "    axs[1].set_xlabel('r [m]')\n",
    "    axs[1].set_ylabel('z [m]')\n",
    "    axs[1].plot(\n",
    "        DB_separatrix_200_test_ConvNet[ind_plot,:,0],\n",
    "        DB_separatrix_200_test_ConvNet[ind_plot,:,1],\n",
    "        c='g')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc60544-5a19-493b-9a7b-bb3e3751f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[B_pickup signals, coil currents, p-profile]\n",
    "X_data = np.column_stack([\n",
    "    DB_meas_Bpickup_test_ConvNet,\n",
    "    DB_coils_curr_test_ConvNet,\n",
    "    DB_p_test_ConvNet\n",
    "])\n",
    "\n",
    "# The target: 2D poloidal flux map for each sample\n",
    "y_data = DB_psi_pixel_test_ConvNet  # shape: (num_samples, nR, nZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c570c6-1188-407e-b890-047320b0f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = X_data.shape[0]\n",
    "indices = np.arange(num_samples)\n",
    "\n",
    "id_train, id_test = train_test_split(indices, test_size=0.35, random_state=42)\n",
    "\n",
    "X_train = X_data[id_train, :]\n",
    "X_test  = X_data[id_test, :]\n",
    "\n",
    "y_train = y_data[id_train, :, :]\n",
    "y_test  = y_data[id_test, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_laplacian(psi):\n",
    "    \"\"\"\n",
    "    Applies a 2D Laplacian to each (nR, nZ) flux map using TensorFlow to compute ∆ψ\n",
    "    Input shape: (batch, nR, nZ)\n",
    "    Output shape: (batch, nR, nZ)\n",
    "    \"\"\"\n",
    "    psi = tf.convert_to_tensor(psi, dtype=tf.float32) # 2D flux map\n",
    "    # y shape: (num_samples, nR, nZ)\n",
    "    psi = tf.expand_dims(psi, axis=-1) # reshape because so output is (batch, nR, nZ, 1)\n",
    "\n",
    "    # 2D convolution discrete version of Laplacian kernel sourced from online:\n",
    "    laplacian_kernel = tf.constant([\n",
    "        [0.,  1., 0.],\n",
    "        [1., -4., 1.],\n",
    "        [0.,  1., 0.]\n",
    "    ], dtype=tf.float32)\n",
    "    laplacian_kernel = tf.reshape(laplacian_kernel, [3, 3, 1, 1])\n",
    "\n",
    "    # convolution\n",
    "    delta_psi = tf.nn.conv2d(psi, laplacian_kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    # remove the last dimension to return to original shape\n",
    "    return tf.squeeze(delta_psi, axis=-1)\n",
    "\n",
    "def loss_function_29(y, y_pred):\n",
    "    \"\"\"\n",
    "    Computes eq. 29: L^*_Δ(ψ, ψ^p) = (1/M) * Σ (Δ*ψ - Δ*ψ^p)^2\n",
    "    \"\"\"\n",
    "    delta_psi = apply_laplacian(y)\n",
    "    delta_psi_pred = apply_laplacian(y_pred)\n",
    "    return tf.reduce_mean(tf.square(delta_psi - delta_psi_pred))\n",
    "\n",
    "def hybrid_loss(y_true, y_pred, λ=1.0):\n",
    "    lap_true = apply_laplacian(y_true)\n",
    "    lap_pred = apply_laplacian(y_pred)\n",
    "    lap_loss = tf.reduce_mean(tf.square(lap_true - lap_pred))\n",
    "    l2_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    return lap_loss + λ * l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64a13a-a047-402b-a816-ef392dacd9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db946c8c-ff3e-43c4-b3bc-f6bea5221b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_r = y_train.shape[1]  # number of radial points\n",
    "n_z = y_train.shape[2]  # number of vertical points\n",
    "out_size = n_r * n_z    # flatten the 2D flux map\n",
    "\n",
    "def build_dense_model(input_dim, output_dim):\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(128, activation='relu')(inputs)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(output_dim, activation='linear')(x) # added dense layer to output flat vector\n",
    "    outputs = layers.Reshape((n_r, n_z))(x) # reshaped output layer\n",
    "    # outputs = layers.Dense(output_dim, activation='linear')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss=lambda y, y_pred: hybrid_loss(y, y_pred, λ=1.0))\n",
    "    return model\n",
    "\n",
    "model = build_dense_model(input_dim=X_train.shape[1], output_dim=out_size)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ea650-aea0-4f21-99fc-b6c35907baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_flat = y_train.reshape(y_train.shape[0], -1)  # shape: (N, nR*nZ)\n",
    "# y_test_flat  = y_test.reshape(y_test.shape[0], -1)\n",
    "\n",
    "# history = model.fit(X_train, y_train_flat,\n",
    "                    # validation_data=(X_test, y_test_flat),\n",
    "                    # epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=120, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8759c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d684b12-cc11-42c1-9616-9d71b0c24f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "rel_error = np.linalg.norm(y_pred.reshape(y_test.shape[0], -1) - \n",
    "                           y_test.reshape(y_test.shape[0], -1), axis=1) / \\\n",
    "            np.linalg.norm(y_test.reshape(y_test.shape[0], -1), axis=1)\n",
    "\n",
    "print(\"Mean relative error:\", np.mean(rel_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a59d6-5118-4869-954d-c7e96f05dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(id_test)-1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot reference psi\n",
    "cs0 = axs[0].contourf(RR_pixels, ZZ_pixels, y_test[i], 20)\n",
    "axs[0].set_title(r'$\\psi_{ref}$')\n",
    "axs[0].set_aspect('equal')\n",
    "fig.colorbar(cs0, ax=axs[0])\n",
    "\n",
    "# Plot predicted psi\n",
    "cs1 = axs[1].contourf(RR_pixels, ZZ_pixels, y_pred[i], 20)\n",
    "axs[1].set_title(r'$\\psi_{pred}$')\n",
    "axs[1].set_aspect('equal')\n",
    "fig.colorbar(cs1, ax=axs[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5371cf9-69b2-4ef9-81ed-eb54addd1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = np.mean((y_pred_test.reshape(y_test.shape[0], -1) - y_test.reshape(y_test.shape[0], -1))**2)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d002313-0ab5-48a1-88ba-3a8621497d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten predictions and ground truth for train and test\n",
    "y_train_pred = model.predict(X_train).reshape(y_train.shape[0], -1)\n",
    "y_test_pred  = model.predict(X_test).reshape(y_test.shape[0], -1)\n",
    "\n",
    "y_train_flat = y_train.reshape(y_train.shape[0], -1)\n",
    "y_test_flat  = y_test.reshape(y_test.shape[0], -1)\n",
    "\n",
    "# R^2 scores\n",
    "r2_train = r2_score(y_train_flat, y_train_pred) * 100\n",
    "r2_test  = r2_score(y_test_flat, y_test_pred) * 100\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_train_flat, y_train_pred, s=0.1, label='train', alpha=0.5)\n",
    "plt.scatter(y_test_flat, y_test_pred, s=0.1, label='test', alpha=0.5)\n",
    "plt.plot([-40, 50], [-40, 50], 'k--', label='perfect')  # diagonal line\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(f\"Rsquared_train = {r2_train:.2f}, Rsquared_test = {r2_test:.2f}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"history_laplacian.json\", \"w\") as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da228f34-de7d-4740-a599-6fe2a2b66476",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test  = model.predict(X_test)\n",
    "\n",
    "# y_pred_train = y_pred_train_flat.reshape(-1, n_r, n_z)# Reshape back to 2D flux\n",
    "# y_pred_test  = y_pred_test_flat.reshape(-1, n_r, n_z)\n",
    "\n",
    "# reshaped to be flat\n",
    "y_pred_train_flat = y_pred_train.reshape(y_pred_train.shape[0], -1)\n",
    "y_pred_test_flat = y_pred_test.reshape(y_pred_test.shape[0], -1)\n",
    "\n",
    "y_train_flat = y_train.reshape(y_train.shape[0], -1)\n",
    "y_test_flat = y_test.reshape(y_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782ba87-f4b8-4f6e-9925-34bbc400b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_flat = y_train.reshape(y_train.shape[0], -1)  # shape: (N, nR*nZ)\n",
    "# y_test_flat  = y_test.reshape(y_test.shape[0], -1)\n",
    "\n",
    "r2_train = r2_score(y_train_flat, y_pred_train_flat)\n",
    "r2_test  = r2_score(y_test_flat,  y_pred_test_flat)\n",
    "mse_train = mean_squared_error(y_train_flat, y_pred_train_flat)\n",
    "mse_test  = mean_squared_error(y_test_flat,  y_pred_test_flat)\n",
    "\n",
    "print(f\"R² train={r2_train:.4f}, test={r2_test:.4f}\")\n",
    "print(f\"MSE train={mse_train:.6e}, test={mse_test:.6e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5cf59-ce5d-4b1f-9533-c5301a801e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(id_test)-1)\n",
    "\n",
    "psi_ref = y_test[idx,:,:]\n",
    "psi_pred = y_pred_test[idx,:,:]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "#plt.suptitle(f\"Sample index {idx} (Test)\")\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"$\\psi_{Ref}$\")\n",
    "plt.contourf(RR_pixels, ZZ_pixels, psi_ref, 30)\n",
    "plt.colorbar()\n",
    "plt.axis('equal')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"$\\psi_{pred}$\")\n",
    "plt.contourf(RR_pixels, ZZ_pixels, psi_pred, 30)\n",
    "plt.colorbar()\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676d963-c2d7-4c4a-b187-37eb88a24827",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, nR, nZ = DB_psi_pixel_test_ConvNet.shape\n",
    "flux_flat = DB_psi_pixel_test_ConvNet.reshape(N, -1)  # shape: (N, nR*nZ)\n",
    "XP_YN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cbad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = XP_YN.squeeze().astype(np.float32)  # shape: (N,)\n",
    "y_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dab010-640b-4639-b645-3a768ddc4349",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bound_pts = DB_separatrix_200_test_ConvNet.shape[1]  # 200\n",
    "y_boundary = DB_separatrix_200_test_ConvNet.reshape(N, -1).astype(np.float32)  # shape: (N, 400)\n",
    "\n",
    "yindices = np.arange(N)\n",
    "id_train, id_test = train_test_split(yindices, test_size=0.3, random_state=42)\n",
    "id_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = flux_flat[id_train, :]  # shape: (N_train, nR*nZ)\n",
    "X_test  = flux_flat[id_test, :]\n",
    "y_class_train = y_class[id_train]         # shape: (N_train,)\n",
    "y_class_test  = y_class[id_test]\n",
    "y_bound_train = y_boundary[id_train, :]   # shape: (N_train, 400)\n",
    "y_bound_test  = y_boundary[id_test, :]\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ad72a-2103-4e36-a3b9-0926102be66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multi_output_model(n_input, n_boundary):\n",
    "    \"\"\"\n",
    "    n_input: size of flattened flux (nR*nZ)\n",
    "    n_boundary: total boundary coords to predict (200*2 = 400)\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(n_input,))\n",
    "    x = layers.Dense(128, activation='relu')(inputs)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    clas_out = layers.Dense(1, activation='sigmoid', name=\"classification_head\")(x)\n",
    "    bound_out = layers.Dense(n_boundary, activation='linear', name=\"boundary_head\")(x)\n",
    "    model = Model(inputs=inputs, outputs=[clas_out, bound_out])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss={\n",
    "            \"classification_head\": \"binary_crossentropy\",\n",
    "            \"boundary_head\": \"mse\"\n",
    "        },\n",
    "        metrics={\n",
    "            \"classification_head\": [\"accuracy\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return model\n",
    "n_input = X_train_scaled.shape[1]  # nR*nZ\n",
    "n_boundary = y_bound_train.shape[1]  # 400\n",
    "model_multi = build_multi_output_model(n_input, n_boundary)\n",
    "model_multi.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ae2a7",
   "metadata": {},
   "source": [
    "## Defining Loss Function\n",
    "* Loss= $\\alpha_{1} \\|\\psi_{pred} − \\psi_{ref}\\|^{2} + \\alpha_{2} \\|\\Delta^{*}\\psi_{pred} − \\Delta^{*}\\psi_{ref}\\|^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cl = model_multi.fit(\n",
    "    X_train_scaled,\n",
    "    [y_class_train, y_bound_train],\n",
    "    validation_data=(\n",
    "        X_test_scaled,\n",
    "        [y_class_test, y_bound_test]\n",
    "    ),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "y_class_pred_train, y_bound_pred_train = model_multi.predict(X_train_scaled)\n",
    "y_class_pred_test,  y_bound_pred_test  = model_multi.predict(X_test_scaled)\n",
    "y_class_bin_train = (y_class_pred_train > 0.5).astype(int).ravel()\n",
    "y_class_bin_test  = (y_class_pred_test  > 0.5).astype(int).ravel()\n",
    "acc_train = accuracy_score(y_class_train, y_class_bin_train)\n",
    "acc_test  = accuracy_score(y_class_test,  y_class_bin_test)\n",
    "\n",
    "f1_train  = f1_score(y_class_train, y_class_bin_train)\n",
    "f1_test   = f1_score(y_class_test,  y_class_bin_test)\n",
    "\n",
    "print(f\"Classification - TRAIN: Acc={acc_train:.3f}, F1={f1_train:.3f}\")\n",
    "print(f\"Classification - TEST:  Acc={acc_test:.3f},  F1={f1_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd3e8b-a851-4f8d-ab57-5efc787e586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bound_train_flat = y_bound_train.reshape(-1)\n",
    "y_bound_pred_train_flat = y_bound_pred_train.reshape(-1)\n",
    "\n",
    "r2_bound_train = r2_score(y_bound_train_flat, y_bound_pred_train_flat)\n",
    "\n",
    "y_bound_test_flat = y_bound_test.reshape(-1)\n",
    "y_bound_pred_test_flat = y_bound_pred_test.reshape(-1)\n",
    "r2_bound_test  = r2_score(y_bound_test_flat, y_bound_pred_test_flat)\n",
    "print(f\"Boundary R² - TRAIN: {r2_bound_train:.4f}, TEST: {r2_bound_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34320e-c821-4df4-ab64-f3d1163feda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    idx = random.randint(0, len(id_test)-1)\n",
    "    true_label = y_class_test[idx]\n",
    "    pred_prob  = y_class_pred_test[idx][0]\n",
    "    pred_label = y_class_bin_test[idx]\n",
    "\n",
    "    print(f\"Sample {idx}: True label={true_label} / Pred prob={pred_prob:.3f} / Pred label={pred_label}\")\n",
    "\n",
    "idx = random.randint(0, len(id_test)-1)\n",
    "bound_true = y_bound_test[idx,:].reshape(-1,2)\n",
    "bound_pred = y_bound_pred_test[idx,:].reshape(-1,2)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "psi_2d = DB_psi_pixel_test_ConvNet[id_test[idx], :, :]\n",
    "plt.contour(RR_pixels, ZZ_pixels, psi_2d, 40)\n",
    "plt.colorbar(label=\"Poloidal Flux\")\n",
    "plt.plot(bound_true[:,0], bound_true[:,1], 'b--', label=\"True LCFS\")\n",
    "plt.plot(bound_pred[:,0], bound_pred[:,1], 'g-', markersize=2, label=\"Pred LCFS\")\n",
    "plt.legend(fontsize=18)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_meas_Bpickup_test_ConvNet[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot loss vs epochs\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.semilogy(train_loss, label='Training Loss')\n",
    "plt.semilogy(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17209a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_GS_operator(psi, RR, ZZ):\n",
    "    \"\"\"\n",
    "    psi shape: (batch, nR, nZ)\n",
    "    RR, ZZ shape: (nR, nZ) - same for all batch\n",
    "    Returns: gs_op shape (batch, nR, nZ)\n",
    "    \"\"\"\n",
    "    # naive center-diff. ignoring edges\n",
    "    # We'll do it in numpy for clarity; for a TF-based approach, we could use tf.nn.conv2d\n",
    "    \n",
    "    # We assume psi, RR, ZZ are np arrays for the moment (custom loop).\n",
    "    # If you want it purely in TF, you'll define a tf function using convolutions.\n",
    "    \n",
    "    batch_size = psi.shape[0]\n",
    "    nR, nZ = psi.shape[1], psi.shape[2]\n",
    "    gs_op = np.zeros_like(psi)\n",
    "    \n",
    "    dR = RR[1,0] - RR[0,0]\n",
    "    dZ = ZZ[0,1] - ZZ[0,0] if nZ>1 else 1e-3  # you must adapt if your grid is different\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        psi_b = psi[b,:,:]\n",
    "        # Laplacian\n",
    "        lap = (\n",
    "            np.roll(psi_b, 1, axis=0) - 2*psi_b + np.roll(psi_b, -1, axis=0)\n",
    "        )/(dR**2) + (\n",
    "            np.roll(psi_b, 1, axis=1) - 2*psi_b + np.roll(psi_b, -1, axis=1)\n",
    "        )/(dZ**2)\n",
    "\n",
    "        # - (1/R)* d(psi)/dR\n",
    "        # R is function of row index => R[i,:]\n",
    "        R_1d = RR[:,0]  # shape (nR,)\n",
    "        dpsi_dR = (\n",
    "            np.roll(psi_b, -1, axis=0) - np.roll(psi_b, 1, axis=0)\n",
    "        )/(2*dR)\n",
    "        \n",
    "        # broadcast R to shape (nR, nZ)\n",
    "        R_2d = np.tile(R_1d.reshape(-1,1), (1,nZ))\n",
    "        out = lap - (1.0/R_2d)*dpsi_dR\n",
    "        gs_op[b,:,:] = out\n",
    "\n",
    "    return gs_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2cc14c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
